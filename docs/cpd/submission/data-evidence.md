# Data course evidence snapshot (draft for assessors)

## Course structure

The Data course is structured into four levels:
- Foundations
- Intermediate
- Advanced
- Summary and games

The progression is designed to move from shared language and basic discipline to applied systems, then to judgement and strategy at scale.

## Levels and progression

- Foundations focuses on core vocabulary, formats, quality, and practical habits.
- Intermediate focuses on applied pipelines, governance, and trust signals.
- Advanced focuses on complex systems, measurement issues, and strategic decision making.
- Summary and games provides recap activities that reinforce existing objectives.

## Learning objectives

Objectives are defined per level and use measurable action verbs.

## Activities and tools

- Structured reading sections with completion indicators
- Tools that produce practice artefacts and structured prompts
- Scenario-based recap activities

## Quizzes and assessment approach

- Quizzes are formative and reinforce interpretation and judgement.
- Completion signals are suitable as evidence points in a CPD log.

## Estimated hours

Hours are conservative estimates to guide learners:
- Foundations: 8
- Intermediate: 10
- Advanced: 12
- Summary and games: 4

## Evidence tracking description

Evidence signals include:
- hours recorded per level
- section completion indicators
- quiz completion events
- tool usage signals where applicable

The platform supports self-directed CPD evidence and does not claim accreditation unless formally granted and published.

# Data course evidence (submission draft)

## Structure and progression

The Data course is structured as:
- Foundations
- Intermediate
- Advanced
- Summary and games

Progression moves from core concepts and formats to applied systems work, then to analysis and judgement at scale.

## Learning objectives

### Foundations
- Understand what data is, how it moves, and why teams misinterpret it.
- Explain common formats and basic storage and querying choices.
- Apply simple quality and stewardship checks to a dataset and a workflow.
- Evaluate basic responsible data risks and trade offs.

### Intermediate
- Explain how schemas and interfaces support real questions and constraints.
- Apply a simple pipeline model from ingestion to serving and identify failure points.
- Analyse trust signals (tests, monitoring, lineage) that make data usable in production.
- Evaluate trade offs between speed, quality, and governance constraints.

### Advanced
- Analyse distribution, sampling, and measurement issues that distort conclusions.
- Explain how advanced system choices (streaming, storage, governance) change data quality and latency.
- Evaluate architectural trade offs for warehouse, lakehouse, and hybrid approaches.
- Apply governance and strategy thinking to keep data ownership and interfaces clear.

### Summary and games
- Explain core data concepts from the track with clear examples.
- Apply concepts to short scenarios and identify what to measure and why.
- Analyse common mistakes and misreads that show up in real data work.
- Evaluate what you would change in a workflow to improve trust and outcomes.

## Activities and tools

Activities include:
- interactive tools for data quality, flow thinking, and applied analysis
- dashboards and templates that produce structured artefacts
- quizzes embedded in the learning flow

## Quizzes and assessment approach

- Quizzes are formative and embedded within levels.
- Completion is recorded as part of learning activity signals.

## Estimated hours

- Foundations: 8 hours
- Intermediate: 10 hours
- Advanced: 12 hours
- Summary and games: 4 hours

These estimates are conservative and intended as guidance for self-directed CPD logging.

## Evidence tracking

Evidence points include:
- recorded hours per level
- section completion indicators
- quiz completion signals
- tool usage signals where applicable


