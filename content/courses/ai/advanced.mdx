---
title: "AI Advanced"
slug: "advanced"
courseId: "ai"
levelId: "advanced"
summary: "My notes on modern model families, agents and how to use them safely in serious systems."
estimatedHours: 12
stepIndex: 2
level: "advanced"
description: "We dive into transformers, generative media, agentic systems, and the checks that keep them safe."
---

import ToolCard from "@/components/notes/ToolCard"
import Callout from "@/components/notes/Callout"
import GlossaryTip from "@/components/notes/GlossaryTip"
import QuizBlock from "@/components/notes/QuizBlock"
import PageNav from "@/components/notes/PageNav"
import SectionProgressToggle from "@/components/notes/SectionProgressToggle"
import LevelProgressBar from "@/components/course/LevelProgressBar"
import CPDTracker from "@/components/CPDTracker"
import DiagramBlock from "@/components/DiagramBlock"
import { aiSectionManifest } from "@/lib/aiSections"
import TokenContextLab from "@/components/notes/tools/ai/advanced/TokenContextLab"
import MiniDiffusionLab from "@/components/notes/tools/ai/advanced/MiniDiffusionLab"
import AgentFlowBuilder from "@/components/notes/tools/ai/advanced/AgentFlowBuilder"
import GovernanceChecklistLab from "@/components/notes/tools/ai/advanced/GovernanceChecklistLab"

# AI Advanced

<LevelProgressBar courseId="ai" levelId="advanced" sectionIds={aiSectionManifest.advanced} />

<CPDTracker courseId="ai" levelId="advanced" estimatedHours={12} />

This level sits after Foundations and Intermediate. We stay with the same calm tone, but we widen the lens to cover the modern model families and the system thinking you need when AI goes into serious products.

## Transformers and large language models

<SectionProgressToggle courseId="ai" levelId="advanced" sectionId="ai-advanced-transformers-and-llms" />

Foundations explained that models learn patterns. Intermediate showed pipelines and metrics. Here we zoom into the architecture that scaled this field: the <GlossaryTip term="transformer">A neural network that uses attention to compare every token in a sequence.</GlossaryTip>.

<GlossaryTip term="attention">A way for the model to decide which parts of the input matter most for the current output.</GlossaryTip> and <GlossaryTip term="self attention">Attention that compares tokens within the same sequence.</GlossaryTip> let the model focus on the right slices of context. Inputs become a stream of <GlossaryTip term="token">Small chunks of text like words or subwords.</GlossaryTip>. A <GlossaryTip term="context window">The maximum number of tokens the model can handle at once.</GlossaryTip> sets a hard limit on how much the model can see. <GlossaryTip term="positional encoding">Signals that mark where each token sits in the sequence.</GlossaryTip> stop the model from losing order.

<DiagramBlock
  title="Transformer flow"
  subtitle="Tokens in, attention blocks, tokens out"
  description="A friendly view of how inputs move through a stack of attention layers before we sample the next tokens."
>
  <div className="grid gap-2 sm:grid-cols-5 text-xs text-slate-800">
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Tokens</p>
      <p className="mt-1">Chunk text into pieces.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Positional signals</p>
      <p className="mt-1">Mark order and distance.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Attention blocks</p>
      <p className="mt-1">Weigh what matters.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Feed forward</p>
      <p className="mt-1">Transform and mix signals.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Output tokens</p>
      <p className="mt-1">Sample the next steps.</p>
    </div>
  </div>
</DiagramBlock>

Large language models are just very big transformers trained on huge datasets. They predict the next token again and again. That is powerful for text, code, and even images when we change how tokens are defined. The practice links back to Intermediate: good prompts, solid retrieval, and a sensible context window beat raw parameter counts.

<ToolCard
  id="ai-transformer-token-lab"
  title="Explore tokens and context"
  description="Paste a short paragraph and see how it turns into tokens, how long the context is and how truncation would affect it."
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-transformers-and-llms"
  cpdMinutesOnUse={10}
>
  <TokenContextLab />
</ToolCard>

<QuizBlock
  id="ai-advanced-transformers-quiz"
  title="Check your understanding of transformers"
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-transformers-and-llms"
  questions={[
    { q: "What does attention decide", a: "Which tokens matter most for the current output." },
    { q: "What is a token", a: "A small chunk of text such as a word or subword." },
    { q: "Why does the context window matter", a: "It caps how much of the prompt and retrieved text the model can see." },
    { q: "Why add positional encoding", a: "To keep track of token order." },
    { q: "How do large language models generate text", a: "By predicting the next token repeatedly." },
    { q: "What risk comes from long prompts", a: "Important context can be truncated." },
  ]}
/>

## Diffusion and generative media

<SectionProgressToggle courseId="ai" levelId="advanced" sectionId="ai-advanced-diffusion-and-generative-media" />

Generative models create new content instead of just labelling it. A <GlossaryTip term="diffusion">Method that adds noise step by step then learns to reverse it.</GlossaryTip> is behind many image and audio models. We work in a <GlossaryTip term="latent space">A compressed space where structure is easier to model.</GlossaryTip> and <GlossaryTip term="sampling">The process of stepping through the denoising path to create outputs.</GlossaryTip>.

<GlossaryTip term="noise">Random values added to hide the original signal.</GlossaryTip> is added repeatedly during training. The model then learns <GlossaryTip term="denoising">How to remove that noise to get back to structure.</GlossaryTip>. Fewer steps make outputs faster. More steps can make them cleaner. You can guide the process with text, images, or both.

<DiagramBlock
  title="Diffusion arc"
  subtitle="From noise to signal"
  description="A tiny view of how an image is pushed into noise and then recovered."
>
  <div className="grid gap-2 sm:grid-cols-4 text-xs text-slate-800">
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Start image</p>
      <p className="mt-1">Simple shape in latent space.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Add noise</p>
      <p className="mt-1">Hide the structure over steps.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Learn to reverse</p>
      <p className="mt-1">Model predicts what to remove.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Sample output</p>
      <p className="mt-1">Noise shrinks and image appears.</p>
    </div>
  </div>
</DiagramBlock>

Practice and risk meet here. Prompts steer the image, but so do safety filters and dataset choices. Generative media can create joy or deep fakes. Keep records of how you sample and what filters you apply. It matters when you need to defend the results.

<ToolCard
  id="ai-diffusion-visual-lab"
  title="Watch a tiny diffusion process"
  description="Step through a tiny example where noise is added and then removed so you can see how a picture slowly appears."
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-diffusion-and-generative-media"
  cpdMinutesOnUse={10}
>
  <MiniDiffusionLab />
</ToolCard>

<QuizBlock
  id="ai-advanced-diffusion-quiz"
  title="Check your understanding of diffusion"
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-diffusion-and-generative-media"
  questions={[
    { q: "What does diffusion do during training", a: "Adds noise and learns how to reverse it." },
    { q: "What is latent space", a: "A compressed space where structure is easier to model." },
    { q: "What does sampling mean here", a: "Stepping through denoising to generate an output." },
    { q: "Why add noise at all", a: "So the model can learn the path back to structure." },
    { q: "How can prompts guide outputs", a: "They nudge the denoising path toward desired features." },
    { q: "Name one risk of generative media", a: "It can create convincing but misleading content." },
  ]}
/>

## Agentic AI and tool use

<SectionProgressToggle courseId="ai" levelId="advanced" sectionId="ai-advanced-agentic-ai-and-tools" />

Intermediate pipelines fed a single model. Agentic systems chain steps. A <GlossaryTip term="planner">Component that decides what to do next.</GlossaryTip> works with an <GlossaryTip term="executor">Component that runs actions.</GlossaryTip> and uses <GlossaryTip term="tool call">A function call that lets the model reach out to search, calculators, or APIs.</GlossaryTip>.

Agents juggle memory. The active <GlossaryTip term="context window">The text the model sees right now.</GlossaryTip> holds the short term state. External <GlossaryTip term="memory">Stored facts pulled back in when needed.</GlossaryTip> keeps long running work moving. That power comes with risk, so we wrap every agent with access rules, logging, and rate limits.

<DiagramBlock
  title="Agent loop"
  subtitle="User to planner to tools to answer"
  description="A simple path that shows where planning, tools, and safety sit."
>
  <div className="grid gap-2 sm:grid-cols-5 text-xs text-slate-800">
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">User goal</p>
      <p className="mt-1">Clear intent.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Planner</p>
      <p className="mt-1">Decides the next tool.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Tools</p>
      <p className="mt-1">Search, code, or APIs.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Memory</p>
      <p className="mt-1">Scratchpad and lookups.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Final answer</p>
      <p className="mt-1">Grounded response.</p>
    </div>
  </div>
</DiagramBlock>

Keep agent flows boring and auditable. Limit the tools they can call, cap the number of steps, and keep humans involved for risky actions. The best agent still fails if you forget simple guardrails.

<ToolCard
  id="ai-agent-flow-lab"
  title="Design an agent flow"
  description="Pick planner, tools and memory to sketch an agent that could solve a real task."
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-agentic-ai-and-tools"
  cpdMinutesOnUse={10}
>
  <AgentFlowBuilder />
</ToolCard>

<QuizBlock
  id="ai-advanced-agentic-quiz"
  title="Check your understanding of agents"
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-agentic-ai-and-tools"
  questions={[
    { q: "What does the planner do", a: "Chooses the next action based on the goal and evidence." },
    { q: "What is a tool call", a: "A function call the model makes to an external action like search or code." },
    { q: "Why add memory outside the model", a: "To keep context across steps without blowing the context window." },
    { q: "Name one guardrail for agents", a: "Restrict tools, add approvals, or log every action." },
    { q: "When do you not need an agent", a: "When one prompt and one response is enough." },
    { q: "Why cap the number of steps", a: "To control cost and avoid loops." },
  ]}
/>

## Evaluation and governance at scale

<SectionProgressToggle courseId="ai" levelId="advanced" sectionId="ai-advanced-evaluation-and-governance" />

Offline metrics from Intermediate stay useful, but live systems need more. <GlossaryTip term="alignment">Keeping model behavior consistent with goals and ethics.</GlossaryTip> and <GlossaryTip term="guardrail">A control that stops unsafe or off-policy outputs.</GlossaryTip> become part of the release checklist. <GlossaryTip term="red teaming">Probing the system with risky or adversarial prompts.</GlossaryTip> and a clear <GlossaryTip term="model card">A short document that states limits and evidence.</GlossaryTip> keep teams honest.

<DiagramBlock
  title="AI lifecycle with oversight"
  subtitle="Design, evaluate, monitor, improve"
  description="The loop that keeps systems safe after launch."
>
  <div className="grid gap-2 sm:grid-cols-4 text-xs text-slate-800">
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Design</p>
      <p className="mt-1">Goals, data rules, model card.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Evaluate</p>
      <p className="mt-1">Offline metrics and red teaming.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Monitor</p>
      <p className="mt-1">Logs, drift, alerts.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Govern</p>
      <p className="mt-1">Owners, approvals, evidence.</p>
    </div>
  </div>
</DiagramBlock>

Treat AI as a system, not a feature. Keep owners for every control. Capture evidence when you run tests or respond to incidents. The calmer and clearer the process, the safer the outcomes.

<ToolCard
  id="ai-governance-checklist-lab"
  title="Build an AI governance checklist"
  description="Pick an AI use case and step through a checklist for risk, policy, testing and monitoring, then export a simple action plan."
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-evaluation-and-governance"
  cpdMinutesOnUse={10}
>
  <GovernanceChecklistLab />
</ToolCard>

<QuizBlock
  id="ai-advanced-governance-quiz"
  title="Check your understanding of evaluation and governance"
  courseId="ai"
  levelId="advanced"
  sectionId="ai-advanced-evaluation-and-governance"
  questions={[
    { q: "What is alignment in practice", a: "Keeping model behavior in line with goals and ethics." },
    { q: "Why run red teaming", a: "To find risky behavior before users do." },
    { q: "What belongs in a model card", a: "Purpose, limits, data notes, and evaluation evidence." },
    { q: "Name one runtime monitor", a: "Drift alerts, safety filters, or latency alarms." },
    { q: "Who should own guardrails", a: "Named people with clear accountability." },
    { q: "Why collect evidence", a: "So approvals and fixes are transparent and repeatable." },
  ]}
/>

<Callout variant="explain" title="Final reminder">
Advanced work is about joining the dots. Keep the simple mental models from Foundations, the pipelines from Intermediate, and layer on bigger models, agents, and governance with the same calm habits.
</Callout>

<PageNav prevHref="/ai/intermediate" prevLabel="Intermediate" nextHref="/ai/summary" nextLabel="Summary and games" showTop showBottom />
