---
title: "AI Summary and games"
slug: "summary"
courseId: "ai"
levelId: "summary"
summary: "A recap of the whole AI track with games, scenarios and labs to see what you really remember."
estimatedHours: 4
stepIndex: 3
level: "summary"
description: "Light, playful recap of the AI journey with games, labs and a master quiz."
learningObjectives:
  - "Explain key concepts from the track in plain language without copying definitions."
  - "Apply concepts to short scenarios and identify what matters most."
  - "Analyse mistakes and misconceptions surfaced by the games and quizzes."
  - "Evaluate what you would do next to strengthen weak areas."
---

import ToolCard from "@/components/notes/ToolCard"
import Callout from "@/components/notes/Callout"
import QuizBlock from "@/components/notes/QuizBlock"
import PageNav from "@/components/notes/PageNav"
import LevelProgressBar from "@/components/course/LevelProgressBar"
import CPDTracker from "@/components/CPDTracker"
import DiagramBlock from "@/components/DiagramBlock"
import SectionProgressToggle from "@/components/notes/SectionProgressToggle"
import { aiSectionManifest } from "@/lib/aiSections"
import ConceptMatchGame from "@/components/notes/tools/ai/summary/ConceptMatchGame"
import OddOneOutGame from "@/components/notes/tools/ai/summary/OddOneOutGame"
import ScenarioClinicGame from "@/components/notes/tools/ai/summary/ScenarioClinicGame"
import MiniProjectDesigner from "@/components/notes/tools/ai/summary/MiniProjectDesigner"
import BuildYourOwnQuiz from "@/components/notes/tools/ai/summary/BuildYourOwnQuiz"

# AI Summary and games

<LevelProgressBar courseId="ai" levelId="summary" sectionIds={aiSectionManifest.summary} />

<CPDTracker courseId="ai" levelId="summary" estimatedHours={4} />

You made it through Foundations, Intermediate and Advanced. This page is a calm recap with a few games and labs. Use it to test what stuck, spot gaps, and build the kind of confidence that comes from knowing what you do not know yet.

## Quick recap

<SectionProgressToggle courseId="ai" levelId="summary" sectionId="ai-summary-concepts" />

Across the track you saw how messy data becomes something a model can use, how models learn patterns and also learn the wrong lessons, and how real products wrap AI in systems, monitoring, and rules.

Foundations gave you the vocabulary: data, labels, features, tokens, training, and evaluation. Intermediate asked the harder questions: what happens when the world changes, when users behave strategically, when your data is biased, or when the cost of a mistake is uneven.

The key shift is this: traditional software is mostly deterministic, which means you can reason about exact behaviour from the code. AI systems are probabilistic, which means you manage distributions, uncertainty, and failure modes. You do not ship a single correct answer. You ship a system that is usually helpful, sometimes wrong, and always in need of feedback and boundaries.

If you remember one practical idea, make it this. Always ask what the model is optimising, what it is blind to, and what you will do when it fails quietly.

<DiagramBlock
  title="The AI journey in one picture"
  description="Data, models, and systems wrapped in safety."
>
  <div className="grid gap-2 sm:grid-cols-4 text-xs text-slate-800">
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Data and tokens</p>
      <p className="mt-1">Collect, clean, and chunk.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Models</p>
      <p className="mt-1">Train, evaluate, avoid overfit.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Systems</p>
      <p className="mt-1">Serve, monitor, add tools.</p>
    </div>
    <div className="rounded-xl border border-slate-200 bg-white p-3">
      <p className="font-semibold text-slate-900">Safety</p>
      <p className="mt-1">Policies, guardrails, evidence.</p>
    </div>
  </div>
</DiagramBlock>

## Games and labs hub

These drills are short. Set a timer, play a couple, and notice which ideas feel strong and which feel fuzzy. Keep it light. The value is in the small moments where your intuition improves.

As you play, connect each result to a real system: search ranking, recommendations, content moderation, summarisation, customer support automation, or a decision assist tool.

### Concept games

Before you start: this is not about memorising definitions. It is about being able to explain an idea clearly enough that you can spot misuse in a meeting.

<ToolCard
  id="ai-summary-flash-cards"
  title="AI flash cards"
  description="Flip through key AI concepts from all three levels and see if you can explain each one in your own words before revealing the answer."
  courseId="ai"
  levelId="summary"
  sectionId="ai-summary-concepts"
  cpdMinutesOnUse={10}
>
  <ConceptMatchGame />
</ToolCard>

After you finish: pick one concept you struggled with and write a one sentence explanation for future you. Then add the real world tie in. Where would this show up in search, recommendations, moderation, or automation.

Before you start: treat this like a sanity check for your mental model. In real work, the odd one out is often the hidden assumption that breaks your system.

<ToolCard
  id="ai-summary-odd-one-out"
  title="Odd one out"
  description="Look at tiny sets of terms or examples and pick the one that does not belong. Great for checking if ideas have clicked."
  courseId="ai"
  levelId="summary"
  sectionId="ai-summary-concepts"
  cpdMinutesOnUse={10}
>
  <OddOneOutGame />
</ToolCard>

After you finish: ask what decision this improves. For example, would you change the data, change the metric, add a human review step, or decide not to automate this at all.

### Scenario labs

<SectionProgressToggle courseId="ai" levelId="summary" sectionId="ai-summary-scenarios" />

Before you start: this is the practical skill. Reading an AI story, spotting what is risky, and choosing the smallest change that improves outcomes.

<ToolCard
  id="ai-summary-scenario-triage"
  title="AI scenario triage"
  description="Walk through short stories that mix data, models and people. Decide what is safe, what is risky and what you would change."
  courseId="ai"
  levelId="summary"
  sectionId="ai-summary-scenarios"
  cpdMinutesOnUse={10}
>
  <ScenarioClinicGame />
</ToolCard>

After you finish: name the system you were implicitly building. Was it search, recommendations, moderation, or automation. Then write down one quiet failure mode you would monitor for, like drift, bias, or users gaming the inputs.

Before you start: focus on building a small system you could actually run, not a magic brain. You are practising scoping, data choices, and where guardrails belong.

<ToolCard
  id="ai-summary-mini-project"
  title="Design a tiny AI project"
  description="Pick a problem, choose a data type, pick a model family and sketch a safe, simple system that could solve it."
  courseId="ai"
  levelId="summary"
  sectionId="ai-summary-scenarios"
  cpdMinutesOnUse={15}
>
  <MiniProjectDesigner />
</ToolCard>

After you finish: imagine you are shipping it into a real product. Who owns it. What is the rollback plan. What happens when users are unhappy. Those questions are the bridge into more advanced AI work.

### Build your own challenge

<SectionProgressToggle courseId="ai" levelId="summary" sectionId="ai-summary-create" />

Before you start: teaching is a cheat code. If you can write a good question, you probably understand the idea. If you cannot, you just found your next learning target.

<ToolCard
  id="ai-summary-build-your-own-quiz"
  title="Build your own AI quiz"
  description="Write your own questions and answers for a friend or future you. Great way to test if you really understand something."
  courseId="ai"
  levelId="summary"
  sectionId="ai-summary-create"
  cpdMinutesOnUse={10}
>
  <BuildYourOwnQuiz />
</ToolCard>

After you finish: add one question that connects to a real system (search, recommendations, moderation, automation) and one question that tests judgement (when to add humans, when to stop the rollout, when not to use AI).

<div className="mt-6 rounded-2xl border border-blue-200 bg-blue-50/50 p-4">
  <div className="flex items-center gap-3">
    <div className="flex-shrink-0">
      <span className="inline-flex h-9 w-9 items-center justify-center rounded-xl border border-blue-200 bg-white text-blue-700">
        <svg className="h-5 w-5" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true">
          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
        </svg>
      </span>
    </div>
    <div className="flex-1">
      <h3 className="text-base font-semibold text-slate-900">More practice games</h3>
      <p className="text-sm text-slate-700">Explore all practice games including cybersecurity, digitalisation, and cross-topic drills.</p>
    </div>
    <a href="/practice" className="button secondary whitespace-nowrap">
      View All Practice Games â†’
    </a>
  </div>
</div>

## Final reflection and next steps

<SectionProgressToggle courseId="ai" levelId="summary" sectionId="ai-summary-master" />

<QuizBlock
  id="ai-summary-master-quiz"
  title="AI track master quiz"
  courseId="ai"
  levelId="summary"
  sectionId="ai-summary-master"
  questions={[
    { q: "Why split data into train, validation and test sets", a: "To tune models without cheating and to get an honest final check." },
    { q: "What does attention do in a transformer", a: "It weighs which tokens matter most for the next output." },
    { q: "Name one signal of overfitting", a: "Validation loss rises while training loss falls." },
    { q: "Why add guardrails to an agent", a: "To control tool use, reduce misuse and keep audit trails." },
    { q: "What is one metric for classification", a: "Precision, recall or F1 depending on the risk." },
    { q: "How do you keep generative media safer", a: "Filter prompts, filter outputs, and keep evidence of the steps you took." },
    { q: "What belongs in a model card", a: "Purpose, limits, data notes, metrics, and owners." },
  ]}
/>

Use these reflection prompts to close the loop:

- What part of AI feels most interesting to you?
- What part still feels confusing?
- What is one small thing you could try at work or at home?

<Callout variant="note" title="Responsible AI reflection">
Keep it real. Where could AI fail quietly in your context, such as wrong but confident answers, missing edge cases, or harmful ranking.

How would bias and data quality show up in practice, such as who gets misclassified, who gets ignored, and whose language is treated as suspicious.

And the most important question: when should you not use AI at all, because the cost of mistakes, the lack of data, or the need for explainability makes automation the wrong move.
</Callout>

<Callout variant="note" title="Next moves">
Revisit any section that felt shaky, then head back to the AI overview or into your CPD dashboard to track the hours you want to invest next.
</Callout>

<PageNav prevHref="/ai/advanced" prevLabel="Advanced" nextHref="/ai" nextLabel="AI course overview" showTop showBottom />
