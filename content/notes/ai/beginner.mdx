---
title: "AI Foundations"
description: "A friendly but serious introduction to data, models and how AI systems work."
level: "foundations"
courseId: "ai"
levelId: "foundations"
summary: "A friendly but serious introduction to data, models and how AI systems work, written as my own notes."
estimatedHours: 8
stepIndex: 0
learningObjectives:
  - "Understand core AI vocabulary (features, labels, training, validation, testing) well enough to explain it clearly."
  - "Explain how simple models learn patterns from data and where they commonly fail."
  - "Apply basic checks for leakage, overfitting, and threshold trade offs using the labs."
  - "Evaluate model outputs with a beginner friendly view of quality, bias, and risk."
---

import ToolCard from "@/components/notes/ToolCard"
import Callout from "@/components/notes/Callout"
import GlossaryTip from "@/components/notes/GlossaryTip"
import QuizBlock from "@/components/notes/QuizBlock"
import PageNav from "@/components/notes/PageNav"
import SectionProgressToggle from "@/components/notes/SectionProgressToggle"
import LevelProgressBar from "@/components/course/LevelProgressBar"
import CPDTracker from "@/components/CPDTracker"
import DiagramBlock from "@/components/DiagramBlock"
import { aiSectionManifest } from "@/lib/aiSections"
import DataNoiseTool from "@/components/notes/tools/ai/beginner/DataNoiseTool"
import FeatureLeakageTool from "@/components/notes/tools/ai/beginner/FeatureLeakageTool"
import ThresholdPlaygroundTool from "@/components/notes/tools/ai/beginner/ThresholdPlaygroundTool"
import ClusteringIntuitionTool from "@/components/notes/tools/ai/beginner/ClusteringIntuitionTool"
import ResponsibleAIPlannerTool from "@/components/notes/tools/ai/beginner/ResponsibleAIPlannerTool"
import AIExamplesExplorerTool from "@/components/notes/tools/ai/beginner/AIExamplesExplorerTool"
import VectorVisualiserTool from "@/components/notes/tools/ai/beginner/VectorVisualiserTool"

# AI Foundations

<LevelProgressBar courseId="ai" levelId="foundations" sectionIds={aiSectionManifest.foundations} />

<CPDTracker courseId="ai" levelId="foundations" estimatedHours={8} />

These notes are a calm path into AI. I focus on meaning first, numbers second, and practice always. The goal is not buzzwords. The goal is to build judgement you can use when you meet real systems.

---

## What AI is and why it matters now

<SectionProgressToggle courseId="ai" levelId="foundations" sectionId="ai-foundations-what-is-ai" />

<Callout variant="concept">
AI is a way of learning patterns from data so a system can make predictions, rank options, or automate decisions.
</Callout>

When people say AI, they often mean a system that takes input, applies a learned pattern, and produces an output. The learned pattern is the <GlossaryTip term="model">A function learned from data that maps inputs to outputs.</GlossaryTip>. The act of learning that pattern is <GlossaryTip term="training">The process of fitting a model to data so it can learn patterns.</GlossaryTip>. Using the trained model to produce results is <GlossaryTip term="inference">Running a trained model to produce predictions on new inputs.</GlossaryTip>.

AI matters now because systems touch decisions that used to be manual. Hiring screens, fraud checks, support routing, and medical triage all use models to move faster. That speed is useful, but it can also amplify mistakes at scale. This is why foundations matter. I need to know what the model is doing before I trust it.

<DiagramBlock
  title="Simple AI flow"
  subtitle="Input goes into a model, output comes out."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Input data -> Model -> Output</div>
    <div>Input: text, images, sensor readings, clicks</div>
    <div>Output: label, score, ranked list, or alert</div>
  </div>
</DiagramBlock>

<DiagramBlock
  title="Rules based vs model based"
  subtitle="Rules are explicit, models are learned from examples."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Rules: if condition then action</div>
    <div>Model: learn the pattern from data</div>
    <div>Rules are easy to explain, models can adapt but need monitoring</div>
  </div>
</DiagramBlock>

<ToolCard
  id="ai-examples-explorer"
  title="Explore simple AI examples"
  description="Toggle between examples like spam filters, recommendation systems and chat assistants, and see what each one takes as input and gives as output."
>
  <AIExamplesExplorerTool />
</ToolCard>

<QuizBlock
  id="ai-foundations-what-is-ai-quiz"
  courseId="ai"
  levelId="foundations"
  sectionId="ai-foundations-what-is-ai"
  title="Quick check: what is AI"
  questions={[
    { q: "What is a model in AI", a: "A learned function that maps inputs to outputs." },
    { q: "What is training", a: "Fitting a model to data so it learns patterns." },
    { q: "What is inference", a: "Using a trained model to make predictions on new inputs." },
    { q: "Give one everyday AI example", a: "Spam filtering, recommendations, or fraud detection." },
    { q: "Why does AI matter now", a: "It scales decisions that used to be manual and can amplify impact." },
    { q: "What is one risk of AI at scale", a: "Mistakes spread faster and affect more people." },
    { q: "What does AI output usually look like", a: "A label, score, or ranked list." },
  ]}
/>

---

## Data and representation

<SectionProgressToggle courseId="ai" levelId="foundations" sectionId="ai-foundations-data-and-representation" />

AI systems learn from data, but data is not magic. Data is measurement plus context, and it often contains noise and bias. I start by naming the <GlossaryTip term="feature">An input attribute used by a model.</GlossaryTip> and the <GlossaryTip term="label">The target value the model should predict.</GlossaryTip>. Then I check if the data actually represents the world I care about.

To make data usable, I clean it, choose features, and turn it into numbers. A numeric representation is how a model sees the world. For text and images, this often uses an <GlossaryTip term="embedding">A numeric vector that represents an item while keeping some of its meaning.</GlossaryTip>. The goal is to keep signal and reduce noise without losing the point of the task.

<DiagramBlock
  title="From raw data to vectors"
  subtitle="Data becomes features, then numbers."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Raw data -> Cleaned data -> Features -> Vector</div>
    <div>Example: Email text -> tokens -> numeric vector</div>
    <div>Example: Sensor readings -> derived features -> model input</div>
  </div>
</DiagramBlock>

<DiagramBlock
  title="Tiny numeric table"
  subtitle="A simple view of features and labels."
>
  <div className="text-xs sm:text-sm leading-5 space-y-1">
    <div>Feature: income = 42</div>
    <div>Feature: missed payments = 1</div>
    <div>Label: repay on time = yes</div>
  </div>
</DiagramBlock>

<ToolCard
  id="vector-visualiser"
  title="See how data becomes numbers"
  description="Type in a few short phrases and see how they turn into numeric vectors, then compare how similar they are."
>
  <VectorVisualiserTool />
</ToolCard>

<ToolCard
  id="signal-noise"
  title="Signal and noise intuition"
  description="Adjust signal and noise to feel how quickly data quality changes."
>
  <DataNoiseTool />
</ToolCard>

<ToolCard
  id="feature-leakage"
  title="Feature leakage check"
  description="Toggle features and see if you are accidentally handing the model the answer."
>
  <FeatureLeakageTool />
</ToolCard>

<QuizBlock
  id="ai-foundations-data-quiz"
  courseId="ai"
  levelId="foundations"
  sectionId="ai-foundations-data-and-representation"
  title="Quick check: data and representation"
  questions={[
    { q: "What is a feature", a: "An input attribute used by a model." },
    { q: "What is a label", a: "The target value the model should learn to predict." },
    { q: "Why do models need numbers", a: "Models operate on numeric vectors, not raw text or images." },
    { q: "What is an embedding", a: "A numeric vector that represents an item while keeping some meaning." },
    { q: "Why does data context matter", a: "It explains what the measurements mean and how they were collected." },
    { q: "What is feature leakage", a: "When a feature reveals the answer and inflates performance." },
    { q: "What happens if noise dominates", a: "The model learns unstable patterns and fails in production." },
    { q: "Why is bias different from noise", a: "Bias is systematic skew, not random variation." },
  ]}
/>

---

## Supervised and unsupervised learning

<SectionProgressToggle courseId="ai" levelId="foundations" sectionId="ai-foundations-learning-paradigms" />

Supervised learning uses examples with labels. The model learns from pairs of input and answer. Unsupervised learning has no labels, so the model searches for structure and patterns without a known target. Both are useful but they answer different questions.

In supervised learning, the model can do <GlossaryTip term="classification">Predicting a category or label.</GlossaryTip> or <GlossaryTip term="regression">Predicting a numeric value.</GlossaryTip>. The decision often depends on a threshold, which is a business choice about how much risk to accept.

<DiagramBlock
  title="Supervised vs unsupervised"
  subtitle="Labels change what the model can learn."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Supervised: inputs + labels -> predict known outcome</div>
    <div>Unsupervised: inputs only -> group or compress</div>
    <div>Supervised answers a question, unsupervised explores structure</div>
  </div>
</DiagramBlock>

<ToolCard
  id="tiny-classifier-lab"
  title="Train a tiny classifier"
  description="Upload or pick a tiny toy dataset and watch a small model learn to separate two classes, with a simple chart of how its guesses improve."
>
  <ThresholdPlaygroundTool />
</ToolCard>

<ToolCard
  id="clustering-intuition"
  title="Clustering intuition"
  description="Change the number of clusters and see how the same data is grouped."
>
  <ClusteringIntuitionTool />
</ToolCard>

<QuizBlock
  id="ai-foundations-learning-quiz"
  courseId="ai"
  levelId="foundations"
  sectionId="ai-foundations-learning-paradigms"
  title="Quick check: learning paradigms"
  questions={[
    { q: "What makes learning supervised", a: "The model trains on examples with labels." },
    { q: "What makes learning unsupervised", a: "The model searches for patterns without labels." },
    { q: "What is classification", a: "Predicting a category or class." },
    { q: "What is regression", a: "Predicting a numeric value." },
    { q: "Why are thresholds important", a: "They control trade offs between false positives and false negatives." },
    { q: "Give an example of unsupervised learning", a: "Grouping customers by behavior without labels." },
    { q: "Why is unsupervised output subjective", a: "Choices like the number of clusters change the result." },
  ]}
/>

---

## Responsible AI basics and limitations

<SectionProgressToggle courseId="ai" levelId="foundations" sectionId="ai-foundations-responsible-ai-basics" />

Responsible AI is about preventing harm and staying accountable. Models can be fast but wrong. They can also encode unfairness without anyone noticing. I watch for <GlossaryTip term="bias">Systematic skew that causes unfair or incorrect outcomes.</GlossaryTip> and for <GlossaryTip term="drift">Changes in data or behavior that reduce model accuracy over time.</GlossaryTip>. I also pay attention to privacy, transparency, and the ability to explain why a decision was made.

AI systems live in a lifecycle: data collection, training, evaluation, deployment, and monitoring. If I skip monitoring, I miss drift and abuse. If I skip human review for high impact decisions, I place people at risk. I treat AI as part of a system, not a magic box.

<DiagramBlock
  title="Responsible AI lifecycle"
  subtitle="Build, deploy, and monitor with accountability."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Data -> Training -> Evaluation -> Deployment -> Monitoring</div>
    <div>Governance surrounds the loop with policies and audits</div>
    <div>Human review protects high impact decisions</div>
  </div>
</DiagramBlock>

<ToolCard
  id="ai-risk-scenarios"
  title="Practice spotting AI risks"
  description="Read short AI stories and practice tagging where bias, privacy or safety issues might appear."
>
  <ResponsibleAIPlannerTool />
</ToolCard>

<QuizBlock
  id="ai-foundations-responsible-quiz"
  courseId="ai"
  levelId="foundations"
  sectionId="ai-foundations-responsible-ai-basics"
  title="Quick check: responsible AI basics"
  questions={[
    { q: "What is bias in AI", a: "Systematic skew that causes unfair or incorrect outcomes." },
    { q: "What is drift", a: "Changes in data or behavior that reduce model accuracy over time." },
    { q: "Why is monitoring required after deployment", a: "Models change behavior as data shifts and need oversight." },
    { q: "Give one high impact scenario that needs human review", a: "Healthcare, hiring, or credit decisions." },
    { q: "Why does privacy matter in AI", a: "Data and logs can expose sensitive information." },
    { q: "What does governance add", a: "Clear accountability, policies, and evidence of compliance." },
    { q: "What is a limitation of AI foundations", a: "Models can be confident but wrong and need oversight." },
  ]}
/>

---

<PageNav prevHref="/ai" prevLabel="AI course overview" nextHref="/ai/intermediate" nextLabel="Intermediate" showTop showBottom />
