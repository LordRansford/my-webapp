---
title: "Applied Cybersecurity"
description: "Level 2 of my cybersecurity course. Applied threat modelling, attack surfaces, identity, detection and risk trade offs with hands-on labs."
level: "applied"
courseId: "cybersecurity"
levelId: "applied"
summary: "Applied threat modelling, attack surfaces, identity, detection and risk trade offs with hands-on labs."
estimatedHours: 12
learningObjectives:
  - "Apply basic threat modelling to a small system, identifying assets, actors, and likely threats."
  - "Explain how authentication, authorisation, sessions, and cookies interact in common web flows."
  - "Analyse simple log signals and relate them to likely misuse or attack paths."
  - "Evaluate trade offs between controls when constraints (cost, usability, risk) conflict."
---

import ProgressBar from '@/components/notes/ProgressBar'
import PageNav from '@/components/notes/PageNav'
import Callout from '@/components/notes/Callout'
import GlossaryTip from '@/components/notes/GlossaryTip'
import ToolCard from '@/components/notes/ToolCard'
import QuizBlock from '@/components/notes/QuizBlock'
import SectionProgressToggle from "@/components/notes/SectionProgressToggle"
import LevelProgressBar from "@/components/course/LevelProgressBar"
import CPDTracker from "@/components/CPDTracker"
import SectionHeader from "@/components/course/SectionHeader"
import SubsectionHeader from "@/components/course/SubsectionHeader"
import BodyText from "@/components/course/BodyText"
import { cyberSections } from "@/lib/cyberSections"

import ThreatScenarioMapper from "@/components/dashboards/cybersecurity/intermediate/ThreatScenarioMapper"
import AttackSurfaceExplorer from "@/components/dashboards/cybersecurity/intermediate/AttackSurfaceExplorer"
import AuthSessionFlowLab from "@/components/dashboards/cybersecurity/intermediate/AuthSessionFlowLab"
import SessionHijackConceptDemo from "@/components/dashboards/cybersecurity/intermediate/SessionHijackConceptDemo"
import LogSignalExplorer from "@/components/dashboards/cybersecurity/intermediate/LogSignalExplorer"
import RiskTradeoffVisualizer from "@/components/dashboards/cybersecurity/intermediate/RiskTradeoffVisualizer"

<ProgressBar mode="scroll" />

# Applied Cybersecurity

<LevelProgressBar courseId="cybersecurity" levelId="applied" sectionIds={cyberSections.applied} />

<CPDTracker courseId="cybersecurity" levelId="applied" estimatedHours={12} />

<BodyText>
  Applied is where we stop describing computers and start thinking like attackers and defenders. We keep the language human, but we anchor every idea to assets, entry points, and the controls that actually change outcomes.
</BodyText>

---

<SectionHeader variant="content" emoji="ðŸŽ¯" id="threat-modelling">
  Threat modelling and attacker thinking
</SectionHeader>

<SectionProgressToggle courseId="cybersecurity" levelId="applied" sectionId="applied-threat-modelling" />

<Callout variant="concept">
Security improves fastest when I can answer one question clearly: what matters, who might attack it, and how it could fail.
</Callout>

A threat model is a simple story about risk. I list each <GlossaryTip term="asset">something that hurts if stolen, changed, or stopped</GlossaryTip>. I name the <GlossaryTip term="threat">who or what could cause harm</GlossaryTip>. I map <GlossaryTip term="attack surface">every way they can interact with the system</GlossaryTip> and the <GlossaryTip term="trust boundary">places where assumptions change</GlossaryTip>. This keeps me focused on reality instead of memorising exotic exploits.

In simple terms: threat modelling is how I decide what to worry about first. It is not a perfect prediction. It is a structured way to turn "security feels scary" into "these three controls will reduce harm most for this system."

In the real world, a cyber person does not sit around naming movie villains. We sit with engineers, product, and sometimes ops, and we ask annoying questions: where does data enter, where does it leave, who can change it, and what happens if it is wrong. We then write down the assumptions and test them.

How it fails: teams either go too broad (a huge diagram nobody reads) or too narrow (only listing SQL injection because it is familiar). Another failure is skipping the human actors: support staff, vendors, and internal admins, which is where many realistic attack paths live.

How to do it well: keep scope small, tie each threat to an entry point, and tie each entry point to a control you can actually implement or measure. Accept trade offs. If a control adds friction, decide where that friction is worth it and where it will be bypassed.

<DiagramBlock
  title="Small threat model in one glance"
  subtitle="People and data cross boundaries; assumptions must be explicit."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>User â†’ Web app â†’ API â†’ Database</div>
    <div className="text-gray-700">Public internet to web app is a trust boundary. API credentials and personal data are assets.</div>
    <div className="text-gray-700">Attacker pushes inputs at the web form and the API. Controls: validation, auth, logging.</div>
  </div>
</DiagramBlock>

Before you use the tool: the goal is not to produce a pretty canvas. The goal is to spot one or two high leverage failures. When you fill it in, focus on what would actually hurt and what someone could realistically do with the access they have.

<ToolCard
  id="threat-model-canvas"
  title="Sketch a simple threat model"
  description="Pick a small system, list assets, actors and trust boundaries, then note where someone might realistically attack it."
>
  <ThreatScenarioMapper />
</ToolCard>

After you use the tool: sanity check your output. Do your threats connect to real entry points, or did you drift into generic fear. Also check whether your controls are specific. "Be secure" is not a control. "Require MFA for staff logins and alert on new device sign in" is closer to a control.

<QuizBlock
  id="applied-threat-modelling"
  courseId="cybersecurity"
  levelId="applied"
  sectionId="applied-threat-modelling"
  title="Quick check: threat modelling"
  questions={[
    { q: "Why start with assets before attacks", a: "Assets tell you what matters, so you focus on controls that protect real value." },
    { q: "What is an attack surface", a: "All the ways an attacker can interact with the system including inputs, interfaces, and dependencies." },
    { q: "What is a trust boundary", a: "A place where assumptions change and data must be validated before it crosses." },
    { q: "Why list actors as well as threats", a: "Different actors have different motives and capabilities which change which controls work." },
    { q: "How do entry points relate to controls", a: "Each entry point should have clear validation, authentication, and monitoring tied to it." },
    { q: "What makes a threat model useful", a: "It guides where to test and where to place controls, not just a diagram for decoration." },
  ]}
/>

---

<CaseStudy
  id="equifax-2017-breach"
  title="Equifax Data Breach (2017)"
  summary="How an unpatched Apache Struts vulnerability led to the exposure of 147 million people's personal and financial data"
  industry="Financial Services"
  year="2017"
  impact="$700M+ settlement + massive reputational damage"
  learningObjectives={["Vulnerability management", "Attack surfaces", "Patch management"]}
  difficulty="intermediate"
>
  <Timeline>
    <TimelineEvent date="March 7, 2017">
      Apache Struts vulnerability (CVE-2017-5638) publicly disclosed with patch available
    </TimelineEvent>
    <TimelineEvent date="March 9, 2017">
      U.S. CERT and DHS issue alert about the critical vulnerability
    </TimelineEvent>
    <TimelineEvent date="Mid-March 2017">
      Attackers exploit the unpatched vulnerability on Equifax systems
    </TimelineEvent>
    <TimelineEvent date="March-July 2017">
      Attackers maintain access for ~4 months, exfiltrating data undetected
    </TimelineEvent>
    <TimelineEvent date="July 29, 2017">
      Equifax discovers unusual network traffic and begins investigation
    </TimelineEvent>
    <TimelineEvent date="September 7, 2017">
      Public disclosure of the breach (6 weeks after discovery)
    </TimelineEvent>
    <TimelineEvent date="July 2019">
      $700M settlement announced with FTC, CFPB, and state attorneys general
    </TimelineEvent>
  </Timeline>

  <RootCause>
    A perfect storm of security failures:
    - **Unpatched vulnerability**: Critical Apache Struts flaw (CVE-2017-5638) remained unpatched for months despite public disclosure and available fix
    - **Missed detection**: Security tools failed to identify the vulnerable version during scanning
    - **Weak segmentation**: Attackers could move laterally from web servers to databases without effective network controls
    - **Certificate expiry**: SSL certificate on monitoring tool expired, disabling inspection of encrypted traffic for 19 months
    - **Inadequate logging**: Lack of comprehensive logging and monitoring made attacker activity invisible for 4 months
    - **Poor incident response**: 6-week delay between discovery and public disclosure, during which executives sold stock
  </RootCause>

  <TechnicalDetails>
    **The Vulnerability (CVE-2017-5638):**
    - Apache Struts web framework had remote code execution flaw in Jakarta Multipart parser
    - Attackers could send specially crafted HTTP requests to execute arbitrary commands
    - CVSS score: 10.0 (Critical) - as severe as it gets
    
    **The Attack Chain:**
    1. **Initial access**: Exploited unpatched Struts vulnerability on Equifax web portal
    2. **Reconnaissance**: Mapped internal network and located databases containing consumer data
    3. **Privilege escalation**: Leveraged weak credentials and misconfigurations to access additional systems
    4. **Data exfiltration**: Slowly extracted 147.9M records over 76 days to avoid detection
    5. **Persistence**: Maintained backdoors and access points throughout the environment
    
    **Data Exposed:**
    - Names, SSNs, birth dates, addresses (147M people)
    - Credit card numbers (209K people)
    - Drivers license numbers (182K people)
    
    **How it relates to Applied Cybersecurity concepts:**
    - **Attack surface**: Public-facing web application was the entry point
    - **Vulnerability management failure**: Known, critical vulnerability with available patch was not applied
    - **Logging and monitoring gap**: 4 months of malicious activity went undetected
    - **Network segmentation**: Flat network allowed lateral movement from web tier to database tier
  </TechnicalDetails>

  <ImpactAnalysis
    financial="$700M+ settlement, $1.4B in security improvements, countless incident response costs, stock price drop"
    operational="Complete security program overhaul, replacement of leadership including CEO and CSO, ongoing monitoring obligations"
    reputational="Became the poster child for security negligence. Consumer trust destroyed. 'Equifax' became synonymous with breach"
    legal="Congressional hearings, FTC investigation, state AG investigations, class action lawsuits, potential criminal charges for insider trading"
  />

  <LessonsLearned>
    **For intermediate learners, this case study teaches:**
    
    1. **Patch management is life-or-death**: A known, critical vulnerability with a public patch remained unpatched. This is inexcusable for a security-critical organization. Develop a process:
       - Monitor vulnerability disclosures (CVEs, vendor alerts)
       - Assess severity in your context (is the vulnerable component exposed?)
       - Test patches in non-production first
       - Deploy emergency patches for critical vulnerabilities within days, not months
    
    2. **Asset inventory is foundational**: Equifax likely didn't have complete visibility into all systems running Apache Struts. You can't patch what you don't know exists.
    
    3. **Defense in depth matters**: The vulnerability was the entry point, but lack of segmentation, monitoring, and access controls turned it into a catastrophic breach. Multiple layers could have limited damage:
       - Web application firewall (WAF) might have blocked exploit attempts
       - Network segmentation would have limited lateral movement
       - Database access controls could have prevented mass exfiltration
       - Proper monitoring would have detected unusual queries
    
    4. **Monitoring must actually be monitored**: Having security tools is useless if they're not working (expired SSL cert), not configured correctly, or no one is watching alerts
    
    5. **Incident response includes communication**: The 6-week delay in disclosure made everything worse. Have a clear IR plan that includes legal, PR, and customer notification timelines
    
    6. **Vulnerability management is a process, not a project**: This isn't "run a scanner once a quarter." It's:
       - Continuous monitoring of vulnerability feeds
       - Automated scanning integrated into CI/CD
       - Clear ownership and SLAs for patching
       - Exception process for systems that can't be patched immediately
       - Regular testing that patches were actually applied
    
    **Practical takeaways:**
    - Prioritize patching by CVSS score + exploitability + exposure (public-facing systems first)
    - Subscribe to vendor security advisories for all software you use
    - Test your monitoring: can you detect a breach in hours/days, not months?
    - Segment networks: web tier â†’ app tier â†’ database tier with strict firewall rules
    - Implement data loss prevention (DLP) to detect mass data exfiltration
  </LessonsLearned>
</CaseStudy>

<SectionHeader variant="content" emoji="ðŸ”" id="attack-surfaces">
  Attack surfaces and common failure classes
</SectionHeader>

<SectionProgressToggle courseId="cybersecurity" levelId="applied" sectionId="applied-attack-surfaces" />

<Callout variant="concept">
Most breaches start with what is exposed, not with exotic zero days.
</Callout>

Operating systems run services, services open ports, and apps expose inputs. The attack surface grows with every feature and every default left unchanged.

In simple terms: attack surface is everything someone can touch. If they can touch it, they can try to break it, confuse it, or use it in a way you did not plan for.

In the real world, what I actually do is inventory exposure: endpoints, admin panels, file uploads, third party scripts, public buckets, test environments, and forgotten subdomains. Then I ask which of those touches sensitive data or powerful actions. That is where I look first.

Common failure classes repeat: <GlossaryTip term="injection">untrusted input treated as instructions</GlossaryTip>, broken access control, unsafe defaults, and <GlossaryTip term="vulnerability">a weakness that can be exploited</GlossaryTip> through a reachable entry point. These are not rare. They are the same few mistakes showing up in different clothes.

How it fails: a feature gets shipped behind a toggle, then the toggle is left on in production. A debug route leaks stack traces. An admin page is "temporary" and ends up indexed by a crawler. A dependency is added and nobody reviews what it loads in the browser.

How to do it well: reduce what is exposed, secure what must be exposed, and make sure every exposed input has validation, authentication where appropriate, and monitoring. The trade off is speed. More exposure makes development easier until the day it makes incident response harder.

<DiagramBlock
  title="Where exposure creeps in"
  subtitle="A simple web app and the inputs that expand attack surface."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Browser â†’ API â†’ Database</div>
    <div>Inputs: login form, file upload, query parameter, admin console</div>
    <div className="text-gray-700">Each input crosses a trust boundary; validation and auth must match the risk.</div>
  </div>
</DiagramBlock>

Before you use the tool: treat each toggle as a real decision. When you turn something on, ask two questions: what new input did I create, and what new assumption did I just make.

<ToolCard
  id="attack-surface-explorer"
  title="Explore attack surfaces"
  description="Toggle features on and off and see how ports, metadata and assumptions expand or shrink your exposure."
>
  <AttackSurfaceExplorer />
</ToolCard>

After you use the tool: look for the "quiet" exposure. A lot of damage comes from boring things like default ports, metadata, admin routes, and third party scripts. The common mistake is focusing only on big obvious inputs and missing the small ones that are easiest to probe.

<QuizBlock
  id="applied-attack-surfaces"
  courseId="cybersecurity"
  levelId="applied"
  sectionId="applied-attack-surfaces"
  title="Quick check: attack surface"
  questions={[
    { q: "What expands attack surface the fastest", a: "New features or services that add inputs, ports, or integrations without controls." },
    { q: "Why is injection dangerous", a: "It turns untrusted input into commands understood by an interpreter." },
    { q: "What is insecure default", a: "A setting that leaves access open, uses weak credentials, or exposes sensitive debug info." },
    { q: "How does metadata leak", a: "Banners, headers and timing can reveal versions or behaviour even if content is encrypted." },
    { q: "Where should validation live", a: "At every untrusted input, server side, before data reaches interpreters or storage." },
    { q: "Why map trust boundaries when reviewing attack surface", a: "They show where assumptions change and where extra checks or isolation are needed." },
  ]}
/>

---

<SectionHeader variant="content" emoji="ðŸ”" id="authentication-sessions">
  Authentication, sessions and access control
</SectionHeader>

<SectionProgressToggle courseId="cybersecurity" levelId="applied" sectionId="applied-auth-sessions-access" />

<Callout variant="concept">
Authentication answers who you are. Authorisation answers what you may do. Sessions remember you between requests. Mixing them up is why many breaches feel trivial.
</Callout>

A session is a bridge in a stateless world. Cookies or tokens are just carriers. Their safety depends on creation, storage, expiry, rotation and server side checks.

In simple terms: a session is the site remembering you between clicks. Without it, every request looks like a stranger. With it, every request is trusted as "you", which is powerful and therefore risky.

In the real world, what I see is not magic crypto. I see teams choosing between cookies and tokens, setting expiries, deciding how logout works, and then finding out that one missing authorisation check exposed data. I also see incidents where a stolen session gets reused from a different device, and nobody notices because there is no monitoring on session anomalies.

Common failures: predictable IDs, missing <GlossaryTip term="privilege escalation">checks that stop users gaining extra rights</GlossaryTip>, and replaying stolen <GlossaryTip term="token">credentials stored in cookies or headers</GlossaryTip>. Another failure is confusing authentication with authorisation: users log in correctly, but the app forgets to check what they are allowed to do.

How to do it well: use secure and HttpOnly cookies where possible, set short lifetimes for high risk sessions, rotate tokens on sensitive events, and invalidate server side on logout. Also treat authorisation as a rule that must be enforced on every request, not just in the UI. The trade off is user convenience. Short sessions can annoy users, so you need to decide where you accept friction and where you compensate with better UX.

<DiagramBlock
  title="Session flow at a glance"
  subtitle="Login creates a session token that rides with each request."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>Login â†’ Server issues token â†’ Browser stores cookie</div>
    <div>Request with cookie â†’ Server checks signature and role</div>
    <div className="text-gray-700">Rotate token on privilege change, expire and invalidate on logout.</div>
  </div>
</DiagramBlock>

Before you use the session flow tool: focus on what is stored where. The browser will happily send cookies back to the server. The question is whether the server should believe them, and under what conditions.

<ToolCard
  id="session-flow-sandbox"
  title="Follow a session through a web app"
  description="Step through login, token or cookie creation and a couple of requests to see how state moves with the user."
>
  <AuthSessionFlowLab />
</ToolCard>

After you use it: check you can explain where the trust comes from. If your model is "the cookie proves it is me forever," you are missing expiry, rotation, and invalidation.

Before you use the hijack demo: this is not teaching you to attack anyone. It is showing why session identifiers are sensitive. If someone gets one, they often do not need your password.

<ToolCard
  id="session-hijack-demo"
  title="See session hijacking in action"
  description="Replay a stolen session identifier and practice the controls that shut it down."
>
  <SessionHijackConceptDemo />
</ToolCard>

After you use it: focus on the controls that break the replay. Short lifetimes, rotation, binding sessions to device signals, and server side invalidation all reduce the window. A common mistake is assuming HTTPS alone prevents session theft. HTTPS protects transport, not your entire browser environment.

<QuizBlock
  id="applied-auth-sessions-access"
  courseId="cybersecurity"
  levelId="applied"
  sectionId="applied-auth-sessions-access"
  title="Quick check: auth and sessions"
  questions={[
    { q: "How do authentication and authorisation differ", a: "Authentication proves identity; authorisation decides what that identity may do." },
    { q: "Why are secure and HttpOnly flags important", a: "They reduce theft by limiting script access and forcing transport security." },
    { q: "What breaks when you skip authorisation", a: "Users can access data or actions they should not, even if they logged in correctly." },
    { q: "How does session rotation help", a: "It invalidates old tokens so stolen tokens are less useful." },
    { q: "Name one sign of privilege escalation", a: "A normal user invoking an admin-only action without being stopped." },
    { q: "What should happen on logout", a: "Server side invalidation of the token or session so reuse fails." },
  ]}
/>

---

<SectionHeader variant="content" emoji="ðŸ“Š" id="logging-monitoring">
  Logging, monitoring and risk thinking
</SectionHeader>

<SectionProgressToggle courseId="cybersecurity" levelId="applied" sectionId="applied-logging-and-risk" />

<Callout variant="concept">
Prevention is never perfect. Good detection shortens the time between a bad action and your response.
</Callout>

I log what I fear: authentication, authorisation, sensitive access, privilege changes, unusual network patterns.

In simple terms: logs are the footprints. Monitoring is deciding which footprints matter. Response is what you do when you see them.

A <GlossaryTip term="log">record of what happened</GlossaryTip> is only useful when it becomes a <GlossaryTip term="signal">something that indicates risk</GlossaryTip> that can turn into an <GlossaryTip term="alert">actionable notification to a human or system</GlossaryTip>. A log line without context is trivia. A signal has enough context that a human can make a decision.

In the real world, this is triage. You see a burst of failed logins, a login from a new country, an API key used at 3am, or a privilege change followed by data export. You decide what to investigate first, and you decide what evidence to preserve.

How it fails: alert fatigue, missing context, and no owner. Teams create rules that fire constantly, then everyone ignores the channel. Or they log everything but cannot search it. Or the person who gets paged has no permission to do anything meaningful.

How to do it well: start with a few high value signals tied to real harm, tune them, and write a short playbook. Decide your trade offs. More alerts can catch more badness but will also burn people out. A smaller set of reliable signals often beats a thousand noisy ones.

Risk thinking joins likelihood and impact. Controls reduce one or both but add cost and friction. This is why a good risk decision is not "maximum security." It is "enough security for what we are protecting, given constraints."

<DiagramBlock
  title="From events to action"
  subtitle="Systems emit logs, you filter for signal, then alert a human or playbook."
>
  <div className="text-xs sm:text-sm leading-5 space-y-2">
    <div>App + Infra â†’ Log pipeline â†’ Storage</div>
    <div>Filters + rules â†’ Alerts â†’ On-call or dashboard</div>
    <div className="text-gray-700">Measure false positives and detection time to tune quality.</div>
  </div>
</DiagramBlock>

Before you use the log triage tool: do not try to read every line. Try to spot the pattern and the story. Ask: what changed, who did it, and what is the plausible next step for an attacker.

<ToolCard
  id="log-triage-lab"
  title="Practice spotting important events in logs"
  description="Scan a realistic log snippet, tag interesting events, and practice deciding what to investigate first."
>
  <LogSignalExplorer />
</ToolCard>

After you use it: check your priorities. A common mistake is chasing the weirdest looking event instead of the highest impact path. Another mistake is ignoring baseline behaviour. "Unusual" only makes sense when you know what normal looks like.

Before you use the risk trade off tool: this is about making trade offs explicit. You are practising how to talk about risk without sounding like a robot or a fortune teller.

<ToolCard
  id="risk-tradeoff-lab"
  title="Play with risk trade offs"
  description="Adjust likelihood, impact and control strength to see residual risk change."
>
  <RiskTradeoffVisualizer />
</ToolCard>

After you use it: focus on residual risk. The common mistake is assuming one control takes risk to zero. Another mistake is ignoring cost and usability until users bypass the control. Good controls reduce harm without breaking the business.

<QuizBlock
  id="applied-logging-and-risk"
  courseId="cybersecurity"
  levelId="applied"
  sectionId="applied-logging-and-risk"
  title="Quick check: logging and risk"
  questions={[
    { q: "Why log authentication and authorisation events", a: "They reveal misuse of accounts and changes to access." },
    { q: "What makes a good signal", a: "It is reliable, contextual, and actionable without drowning people in noise." },
    { q: "Why do too many alerts hurt", a: "Alert fatigue hides real incidents because people start to ignore them." },
    { q: "How does likelihood differ from impact", a: "Likelihood is how often it may happen; impact is how bad it is when it does." },
    { q: "What is residual risk", a: "The risk that remains after controls are applied." },
    { q: "Who owns responding to alerts", a: "A named person or team so responsibility is clear." },
  ]}
/>

---

<PageNav
  prevHref="/cybersecurity/beginner"
  prevLabel="Foundations"
  nextHref="/cybersecurity/advanced"
  nextLabel="Practice and strategy"
  showTop
  showBottom
/>
