{
  "version": 3,
  "sources": [],
  "debugId": "4972f76c-b981-0b21-5bbb-e1c5bf8e5930",
  "sections": [
    {"offset": {"line": 1, "column": 0}, "map": {"version":3,"sources":["../../../src/lib/db/prisma.ts","../../../src/lib/security/rateLimit.ts","../../../src/lib/security/origin.ts","../../../src/lib/security/requestLog.ts","../../../src/lib/mentor/retrieveContent.ts","../../../src/lib/mentor/llm.ts"],"sourcesContent":["import { PrismaClient } from \"@prisma/client\";\n\n// Default DB for local dev when env is missing.\n// This keeps local dev lightweight and avoids \"silent\" runtime failures.\nif (!process.env.DATABASE_URL) {\n  process.env.DATABASE_URL = \"file:./data/dev.db\";\n}\n\ndeclare global {\n  var __prisma: PrismaClient | undefined;\n}\n\nexport const prisma: PrismaClient =\n  global.__prisma ||\n  new PrismaClient({\n    log: [\"error\"],\n  });\n\nif (process.env.NODE_ENV !== \"production\") {\n  global.__prisma = prisma;\n}\n\n\n","import { NextResponse } from \"next/server\";\nimport crypto from \"crypto\";\n\ntype Options = {\n  keyPrefix: string;\n  limit: number;\n  windowMs: number;\n  keySuffix?: string;\n  message?: string;\n};\n\ntype Entry = { count: number; resetAt: number };\n\nconst buckets = new Map<string, Entry>();\n\nfunction hash(value: string) {\n  return crypto.createHash(\"sha256\").update(value).digest(\"hex\").slice(0, 24);\n}\n\nfunction getClientKey(req: Request, keySuffix?: string) {\n  // Privacy: we do not persist IPs; we only keep a short-lived hash in memory.\n  const forwarded = req.headers.get(\"x-forwarded-for\") || \"\";\n  const ip = forwarded.split(\",\")[0]?.trim() || req.headers.get(\"x-real-ip\") || \"unknown\";\n  const ua = req.headers.get(\"user-agent\") || \"unknown\";\n  return hash(`${ip}|${ua}|${keySuffix || \"\"}`);\n}\n\nexport function rateLimit(req: Request, opts: Options) {\n  const now = Date.now();\n  const key = `${opts.keyPrefix}:${getClientKey(req, opts.keySuffix)}`;\n  const existing = buckets.get(key);\n  if (!existing || existing.resetAt <= now) {\n    buckets.set(key, { count: 1, resetAt: now + opts.windowMs });\n    return null;\n  }\n  existing.count += 1;\n  if (existing.count > opts.limit) {\n    const retryAfter = Math.max(1, Math.ceil((existing.resetAt - now) / 1000));\n    return NextResponse.json(\n      { error: opts.message || \"Too many requests. Please try again shortly.\" },\n      { status: 429, headers: { \"retry-after\": String(retryAfter) } }\n    );\n  }\n  return null;\n}\n\n\n","import { NextResponse } from \"next/server\";\n\nfunction getSiteOrigin() {\n  try {\n    return new URL(process.env.NEXT_PUBLIC_SITE_URL || \"http://localhost:3000\").origin;\n  } catch {\n    return \"http://localhost:3000\";\n  }\n}\n\nexport function requireSameOrigin(req: Request) {\n  // Lightweight CSRF protection for browser-invoked state changes:\n  // require Origin/Referer to match our configured site origin.\n  const origin = req.headers.get(\"origin\");\n  const referer = req.headers.get(\"referer\");\n  const siteOrigin = getSiteOrigin();\n\n  const candidate = origin || (referer ? (() => { try { return new URL(referer).origin; } catch { return null; } })() : null);\n  if (!candidate) {\n    return NextResponse.json({ error: \"Missing origin\" }, { status: 403 });\n  }\n  if (candidate !== siteOrigin) {\n    return NextResponse.json({ error: \"Invalid origin\" }, { status: 403 });\n  }\n  return null;\n}\n\n\n","import crypto from \"crypto\";\n\nexport function getRequestId(req: Request) {\n  return req.headers.get(\"x-request-id\") || crypto.randomUUID();\n}\n\nexport async function withRequestLogging<T>(\n  req: Request,\n  meta: { route: string },\n  fn: (ctx: { requestId: string }) => Promise<T>\n) {\n  const requestId = getRequestId(req);\n  const start = Date.now();\n  try {\n    const result = await fn({ requestId });\n    const durationMs = Date.now() - start;\n    console.info(\"req\", { requestId, route: meta.route, status: \"ok\", durationMs });\n    return result;\n  } catch (err: any) {\n    const durationMs = Date.now() - start;\n    console.error(\"req\", { requestId, route: meta.route, status: \"error\", durationMs, message: err?.message || \"error\" });\n    throw err;\n  }\n}\n\n\n","import fs from \"node:fs\";\nimport path from \"node:path\";\n\nexport type ContentSection = {\n  depth: number;\n  title: string;\n  anchor: string;\n  excerpt: string;\n};\n\nexport type ContentPage = {\n  route: string;\n  title: string;\n  sourcePath: string;\n  sections: ContentSection[];\n};\n\nexport type ContentIndex = {\n  generatedAt: string;\n  pages: ContentPage[];\n};\n\nexport type Citation = {\n  title: string;\n  href: string;\n  why: string;\n  pageTitle: string;\n  pageRoute: string;\n  anchor: string;\n  score: number;\n};\n\nfunction loadIndex(): ContentIndex {\n  const abs = path.join(process.cwd(), \"public\", \"content-index.json\");\n  if (!fs.existsSync(abs)) {\n    throw new Error(\"Missing public/content-index.json. Run npm run build:content-index.\");\n  }\n  const raw = fs.readFileSync(abs, \"utf8\");\n  return JSON.parse(raw);\n}\n\nfunction normalise(text: string) {\n  return String(text || \"\").toLowerCase().replace(/[^a-z0-9\\s]/g, \" \").replace(/\\s+/g, \" \").trim();\n}\n\n// Expand common variations and synonyms\nfunction expandTerms(terms: string[]): string[] {\n  const expanded = new Set<string>(terms);\n  \n  for (const term of terms) {\n    // Handle common variations\n    if (term === \"digitalisation\" || term === \"digitalization\") {\n      expanded.add(\"digitalisation\");\n      expanded.add(\"digitalization\");\n      expanded.add(\"digital\");\n      expanded.add(\"digitize\");\n      expanded.add(\"digitise\");\n    }\n    if (term === \"digital\") {\n      expanded.add(\"digitalisation\");\n      expanded.add(\"digitalization\");\n    }\n  }\n  \n  return Array.from(expanded);\n}\n\nconst STOPWORDS = new Set([\n  \"a\",\n  \"an\",\n  \"and\",\n  \"are\",\n  \"as\",\n  \"at\",\n  \"be\",\n  \"by\",\n  \"can\",\n  \"do\",\n  \"does\",\n  \"for\",\n  \"from\",\n  \"how\",\n  \"i\",\n  \"in\",\n  \"is\",\n  \"it\",\n  \"of\",\n  \"on\",\n  \"or\",\n  \"the\",\n  \"this\",\n  \"to\",\n  \"what\",\n  \"when\",\n  \"where\",\n  \"why\",\n  \"with\",\n  \"you\",\n  \"your\",\n]);\n\nfunction scoreSection(terms: string[], section: ContentSection, pageBoost: number) {\n  const titleLower = section.title.toLowerCase();\n  const excerptLower = (section.excerpt || \"\").toLowerCase();\n  const hay = `${titleLower} ${excerptLower}`;\n  let score = 0;\n  \n  for (const t of terms) {\n    if (!t) continue;\n    \n    // Exact title match gets highest score\n    if (titleLower === t || titleLower.includes(` ${t} `) || titleLower.startsWith(`${t} `) || titleLower.endsWith(` ${t}`)) {\n      score += 8; // Increased from 4 to 8 for title matches\n    } else if (titleLower.includes(t)) {\n      score += 5; // Partial title match\n    }\n    \n    // Word boundary matches in excerpt\n    const re = new RegExp(`\\\\b${t}\\\\b`, \"gi\");\n    const matches = hay.match(re);\n    if (matches) {\n      score += matches.length * 1.5; // Slightly increased weight\n    }\n    \n    // Also check for partial matches (for longer terms)\n    if (t.length >= 4) {\n      const partialRe = new RegExp(t, \"gi\");\n      const partialMatches = hay.match(partialRe);\n      if (partialMatches && partialMatches.length > (matches?.length || 0)) {\n        score += (partialMatches.length - (matches?.length || 0)) * 0.5;\n      }\n    }\n  }\n  \n  return Math.round(score + pageBoost);\n}\n\nexport function retrieveContent(question: string, currentRoute: string | null, limit = 6) {\n  const q = normalise(question);\n  let terms = q\n    .split(\" \")\n    .filter(Boolean)\n    .filter((t) => t.length >= 2 && !STOPWORDS.has(t)) // Lowered from 3 to 2 to catch more terms\n    .slice(0, 15); // Increased from 12 to 15\n  \n  // Expand terms with variations and synonyms\n  terms = expandTerms(terms);\n  \n  if (!terms.length) return { matches: [] as Citation[], weak: true };\n\n  const idx = loadIndex();\n  const scored: Citation[] = [];\n\n  for (const page of idx.pages) {\n    const isCurrent = currentRoute && page.route === currentRoute;\n    const pageBoost = isCurrent ? 6 : currentRoute && page.route.startsWith(currentRoute.split(\"/\")[1] || \"\") ? 1 : 0;\n    \n    // Also score the page title itself\n    const pageTitleLower = page.title.toLowerCase();\n    let pageTitleScore = 0;\n    for (const term of terms) {\n      if (pageTitleLower.includes(term)) {\n        pageTitleScore += 3; // Boost for page title matches\n      }\n    }\n\n    for (const section of page.sections) {\n      if (!section.anchor) continue;\n      const score = scoreSection(terms, section, pageBoost + pageTitleScore);\n      if (score <= 0) continue;\n      scored.push({\n        title: section.title,\n        href: `${page.route}#${section.anchor}`,\n        why: section.excerpt ? section.excerpt.slice(0, 200) : \"Relevant section in the notes.\", // Increased excerpt length\n        pageTitle: page.title,\n        pageRoute: page.route,\n        anchor: section.anchor,\n        score,\n      });\n    }\n    \n    // If page title matches well but no sections matched, add the page itself\n    if (pageTitleScore >= 3 && !scored.some(s => s.pageRoute === page.route)) {\n      scored.push({\n        title: page.title,\n        href: page.route,\n        why: `Page about ${page.title}`,\n        pageTitle: page.title,\n        pageRoute: page.route,\n        anchor: \"\",\n        score: pageTitleScore,\n      });\n    }\n  }\n\n  scored.sort((a, b) => b.score - a.score);\n  const top = scored.slice(0, limit);\n  // Much lower threshold: score of 2+ means we found something relevant\n  const weak = top.length === 0 || top[0].score < 2;\n  return { matches: top, weak };\n}\n\n\n","/**\n * LLM Integration for Mentor RAG System\n * \n * Supports multiple LLM providers with fallback:\n * - OpenAI (if OPENAI_API_KEY is set)\n * - Together.ai (if TOGETHER_API_KEY is set, uses open source models)\n * - Local Ollama (if OLLAMA_BASE_URL is set)\n * \n * Safety: All responses are grounded in retrieved content only.\n */\n\ntype LLMProvider = \"openai\" | \"together\" | \"ollama\" | \"none\";\n\ntype LLMResponse = {\n  answer: string;\n  tokensUsed?: number;\n  provider: LLMProvider;\n};\n\ntype LLMConfig = {\n  provider: LLMProvider;\n  model?: string;\n  maxTokens?: number;\n  temperature?: number;\n};\n\n/**\n * Detect available LLM provider\n */\nfunction detectProvider(): LLMConfig {\n  // Priority: OpenAI > Together.ai > Ollama\n  if (process.env.OPENAI_API_KEY) {\n    return {\n      provider: \"openai\",\n      model: process.env.OPENAI_MODEL || \"gpt-4o-mini\",\n      maxTokens: 800,\n      temperature: 0.3,\n    };\n  }\n  \n  if (process.env.TOGETHER_API_KEY) {\n    return {\n      provider: \"together\",\n      model: process.env.TOGETHER_MODEL || \"meta-llama/Llama-3.1-8B-Instruct-Turbo\",\n      maxTokens: 800,\n      temperature: 0.3,\n    };\n  }\n  \n  if (process.env.OLLAMA_BASE_URL) {\n    return {\n      provider: \"ollama\",\n      model: process.env.OLLAMA_MODEL || \"llama3.2\",\n      maxTokens: 800,\n      temperature: 0.3,\n    };\n  }\n  \n  return { provider: \"none\" };\n}\n\n/**\n * Generate answer using OpenAI\n */\nasync function generateWithOpenAI(\n  prompt: string,\n  config: { model: string; maxTokens: number; temperature: number }\n): Promise<LLMResponse> {\n  const key = process.env.OPENAI_API_KEY!;\n  const response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      Authorization: `Bearer ${key}`,\n    },\n    body: JSON.stringify({\n      model: config.model,\n      messages: [\n        {\n          role: \"system\",\n          content: `You are a helpful learning mentor for Ransford's Notes, a website about cybersecurity, AI, software architecture, data, and digitalisation. You answer questions based ONLY on the provided context from the website. You provide clear, practical explanations with links to relevant pages. You never make up information that isn't in the context. If the context doesn't contain enough information to answer the question, you say so and suggest where the user might find more information on the website.`,\n        },\n        { role: \"user\", content: prompt },\n      ],\n      max_tokens: config.maxTokens,\n      temperature: config.temperature,\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`OpenAI API error: ${response.status} ${error}`);\n  }\n\n  const data = await response.json();\n  const answer = data.choices?.[0]?.message?.content || \"\";\n  const tokensUsed = data.usage?.total_tokens;\n\n  return { answer, tokensUsed, provider: \"openai\" };\n}\n\n/**\n * Generate answer using Together.ai (open source models)\n */\nasync function generateWithTogether(\n  prompt: string,\n  config: { model: string; maxTokens: number; temperature: number }\n): Promise<LLMResponse> {\n  const key = process.env.TOGETHER_API_KEY!;\n  const response = await fetch(\"https://api.together.xyz/v1/chat/completions\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      Authorization: `Bearer ${key}`,\n    },\n    body: JSON.stringify({\n      model: config.model,\n      messages: [\n        {\n          role: \"system\",\n          content: `You are a helpful learning mentor for Ransford's Notes, a website about cybersecurity, AI, software architecture, data, and digitalisation. You answer questions based ONLY on the provided context from the website. You provide clear, practical explanations with links to relevant pages. You never make up information that isn't in the context. If the context doesn't contain enough information to answer the question, you say so and suggest where the user might find more information on the website.`,\n        },\n        { role: \"user\", content: prompt },\n      ],\n      max_tokens: config.maxTokens,\n      temperature: config.temperature,\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Together.ai API error: ${response.status} ${error}`);\n  }\n\n  const data = await response.json();\n  const answer = data.choices?.[0]?.message?.content || \"\";\n  const tokensUsed = data.usage?.total_tokens;\n\n  return { answer, tokensUsed, provider: \"together\" };\n}\n\n/**\n * Generate answer using Ollama (local)\n */\nasync function generateWithOllama(\n  prompt: string,\n  config: { model: string; maxTokens: number; temperature: number }\n): Promise<LLMResponse> {\n  const baseUrl = process.env.OLLAMA_BASE_URL || \"http://localhost:11434\";\n  const response = await fetch(`${baseUrl}/api/chat`, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({\n      model: config.model,\n      messages: [\n        {\n          role: \"system\",\n          content: `You are a helpful learning mentor for Ransford's Notes, a website about cybersecurity, AI, software architecture, data, and digitalisation. You answer questions based ONLY on the provided context from the website. You provide clear, practical explanations with links to relevant pages. You never make up information that isn't in the context. If the context doesn't contain enough information to answer the question, you say so and suggest where the user might find more information on the website.`,\n        },\n        { role: \"user\", content: prompt },\n      ],\n      options: {\n        num_predict: config.maxTokens,\n        temperature: config.temperature,\n      },\n      stream: false,\n    }),\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Ollama API error: ${response.status} ${error}`);\n  }\n\n  const data = await response.json();\n  const answer = data.message?.content || \"\";\n\n  return { answer, provider: \"ollama\" };\n}\n\n/**\n * Build RAG prompt from retrieved content\n */\nexport function buildRAGPrompt(\n  question: string,\n  retrievedContent: Array<{\n    title: string;\n    href: string;\n    excerpt?: string;\n    text?: string;\n    why?: string;\n  }>,\n  currentPageContext?: { title?: string; pathname?: string }\n): string {\n  const contextParts: string[] = [];\n\n  if (currentPageContext?.title) {\n    contextParts.push(`Current page: ${currentPageContext.title} (${currentPageContext.pathname || \"\"})`);\n  }\n\n  contextParts.push(\"\\nRelevant content from the website:\\n\");\n\n  retrievedContent.forEach((item, idx) => {\n    const text = item.excerpt || item.text || item.why || \"\";\n    contextParts.push(`\\n[Source ${idx + 1}: ${item.title}]`);\n    contextParts.push(`URL: ${item.href}`);\n    contextParts.push(`Content: ${text}`);\n  });\n\n  const context = contextParts.join(\"\\n\");\n\n  return `Answer the following question based ONLY on the context provided below. If the context doesn't contain enough information, say so clearly and suggest relevant pages from the website where the user can learn more.\n\nQuestion: ${question}\n\n${context}\n\nInstructions:\n- Answer the question using only information from the context above\n- Include the exact URLs from the context in your answer using markdown links like [Page Title](URL)\n- If explaining how to use a tool, provide step-by-step instructions based on the context\n- If the context is about a concept (like \"digitalisation\"), provide a clear explanation with links\n- Never make up information that isn't in the context\n- If multiple sources are relevant, reference them all\n\nAnswer:`;\n}\n\n/**\n * Generate answer using available LLM provider\n */\nexport async function generateAnswer(\n  question: string,\n  retrievedContent: Array<{\n    title: string;\n    href: string;\n    excerpt?: string;\n    text?: string;\n    why?: string;\n  }>,\n  currentPageContext?: { title?: string; pathname?: string },\n  timeoutMs = 15000\n): Promise<LLMResponse | null> {\n  const config = detectProvider();\n  \n  if (config.provider === \"none\") {\n    return null;\n  }\n\n  const prompt = buildRAGPrompt(question, retrievedContent, currentPageContext);\n\n  const controller = new AbortController();\n  const timeoutId = setTimeout(() => controller.abort(), timeoutMs);\n\n  try {\n    let result: LLMResponse;\n\n    switch (config.provider) {\n      case \"openai\":\n        result = await generateWithOpenAI(prompt, config as any);\n        break;\n      case \"together\":\n        result = await generateWithTogether(prompt, config as any);\n        break;\n      case \"ollama\":\n        result = await generateWithOllama(prompt, config as any);\n        break;\n      default:\n        return null;\n    }\n\n    clearTimeout(timeoutId);\n    return result;\n  } catch (err) {\n    clearTimeout(timeoutId);\n    if (err instanceof Error && err.name === \"AbortError\") {\n      throw new Error(\"LLM request timed out\");\n    }\n    throw err;\n  }\n}\n\n"],"names":[],"mappings":"2gCAAA,IAAA,EAAA,EAAA,CAAA,CAAA,MAII,CAAC,QAAQ,GAAG,CAAC,YAAY,EAAE,AAC7B,SAAQ,GAAG,CAAC,YAAY,CAAG,oBAAA,EAOtB,IAAM,EACX,OAAO,QAAQ,EACf,IAAI,EAAA,YAAY,CAAC,CACf,IAAK,CAAC,QAAQ,AAChB,gDChBF,IAAA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,QAYA,IAAM,EAAU,IAAI,IAcb,SAAS,EAAU,CAAY,CAAE,CAAa,UACnD,MANM,IAMA,EAAM,KAAK,GAAG,GACd,EAAM,CAAA,EAAG,EAAK,SAAS,CAAC,CAAC,EAAE,CAVC,EAUiB,EAAK,KAVJ,IAUa,CAR3D,EAQwC,AAR5B,EAAI,OAAO,CAAC,GAAG,CAAC,oBAAsB,KAC7C,EAAU,KAAK,CAAC,IAAI,CAAC,EAAE,EAAE,QAAU,EAAI,OAAO,CAAC,GAAG,CAAC,cAAgB,UACxE,EAAK,EAAI,OAAO,CAAC,GAAG,CAAC,eAAiB,UARhC,EASA,CAAA,EATa,AASV,EAAG,CAAC,EAAE,EAAG,CAAC,EAAE,GAAa,GAAA,CAAI,CARrC,EAAA,OAAM,CAAC,UAAU,CAAC,UAAU,MAAM,CAAC,GAAO,MAAM,CAAC,OAAO,KAAK,CAAC,EAAG,KAaP,CAAG,CAC9D,EAAW,EAAQ,GAAG,CAAC,GAC7B,GAAI,CAAC,GAAY,EAAS,OAAO,EAAI,EAEnC,GAFwC,IACxC,EAAQ,GAAG,CAAC,EAAK,CAAE,MAAO,EAAG,QAAS,EAAM,EAAK,QAAQ,AAAC,GACnD,KAGT,GADA,EAAS,KAAK,EAAI,EACd,EAAS,KAAK,CAAG,EAAK,KAAK,CAAE,CAC/B,IAAM,EAAa,KAAK,GAAG,CAAC,EAAG,KAAK,IAAI,CAAC,AAAC,GAAS,OAAO,CAAG,CAAA,CAAG,CAAI,MACpE,OAAO,EAAA,YAAY,CAAC,IAAI,CACtB,CAAE,MAAO,EAAK,OAAO,EAAI,8CAA+C,EACxE,CAAE,OAAQ,IAAK,QAAS,CAAE,cAAe,OAAO,EAAY,CAAE,EAElE,CACA,OAAO,IACT,mDC5CA,IAAA,EAAA,EAAA,CAAA,CAAA,OAUO,SAAS,EAAkB,CAAY,EAG5C,IAAM,EAAS,EAAI,OAAO,CAAC,GAAG,CAAC,UACzB,EAAU,EAAI,OAAO,CAAC,GAAG,CAAC,WAC1B,EAbR,AAaqB,SAbZ,EACP,GAAI,CACF,OAAO,IAAI,IAAI,QAAQ,GAAG,CAAC,oBAAoB,EAAI,yBAAyB,MAAM,AACpF,CAAE,KAAM,CACN,MAAO,uBACT,CACF,IASQ,EAAY,IAAW,EAAU,AAAC,IAAZ,EAAoB,GAAI,CAAE,OAAO,IAAI,IAAI,GAAS,MAAM,AAAE,CAAE,KAAM,CAAE,OAAO,IAAM,EAAE,CAAC,GAAM,IAAA,CAAI,QAC1H,AAAK,EAGD,EAHA,EAGc,EACT,EAAA,CAJO,OAGc,IACT,CAAC,IAAI,CAAC,CAAE,MAAO,gBAAiB,EAAG,CAAE,OAAQ,GAAI,GAE/D,KALE,EAAA,YAAY,CAAC,IAAI,CAAC,CAAE,MAAO,gBAAiB,EAAG,CAAE,OAAQ,GAAI,EAMxE,qICzBA,IAAA,EAAA,EAAA,CAAA,CAAA,QAEO,SAAS,EAAa,CAAY,EACvC,OAAO,EAAI,OAAO,CAAC,GAAG,CAAC,iBAAmB,EAAA,OAAM,CAAC,UAAU,EAC7D,CAEO,eAAe,EACpB,CAAY,CACZ,CAAuB,CACvB,CAA8C,EAE9C,IAAM,EAAY,EAAa,GACzB,EAAQ,KAAK,GAAG,GACtB,GAAI,CACF,IAAM,EAAS,MAAM,EAAG,WAAE,CAAU,GAC9B,EAAa,KAAK,GAAG,GAAK,EAEhC,OADA,QAAQ,IAAI,CAAC,MAAO,WAAE,EAAW,MAAO,EAAK,KAAK,CAAE,OAAQ,gBAAM,CAAW,GACtE,CACT,CAAE,MAAO,EAAU,CACjB,IAAM,EAAa,KAAK,GAAG,GAAK,CAEhC,OADA,QAAQ,KAAK,CAAC,MAAO,CAAE,YAAW,MAAO,EAAK,KAAK,CAAE,OAAQ,mBAAS,EAAY,QAAS,GAAK,SAAW,OAAQ,GAC7G,CACR,CACF,gOCvBA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QAkEA,IAAM,EAAY,IAAI,IAAI,CACxB,IACA,KACA,MACA,MACA,KACA,KACA,KACA,KACA,MACA,KACA,OACA,MACA,OACA,MACA,IACA,KACA,KACA,KACA,KACA,KACA,KACA,MACA,OACA,KACA,OACA,OACA,QACA,MACA,OACA,MACA,OACD,EAsCM,SAAS,EAAgB,CAAgB,CAAE,CAA2B,CAAE,EAAQ,CAAC,EAEtF,IAAI,EAjGG,AAiGK,OAjGE,AAgGM,GAhGE,IAAI,WAAW,GAAG,OAAO,CAAC,eAAgB,KAAK,OAAO,CAAC,OAAQ,KAAK,IAAI,GAkG3F,KAAK,CAAC,KACN,MAAM,CAAC,SACP,MAAM,CAAC,AAAC,GAAM,EAAE,MAAM,EAAI,GAAK,CAAC,EAAU,GAAG,CAAC,IAAI,AAClD,KAAK,CAAC,EAAG,IAKZ,CALiB,EAKb,CAAC,CAFL,EApGF,AAoGU,SApGW,AAAZ,CAA2B,EAClC,IAAM,EAAW,EAgG0B,EAhGtB,CA+F0E,GA/F9D,GAEjC,IAAK,IAAM,KAAQ,GAEJ,GAFW,gBAEpB,GAAsC,mBAAT,CAAS,GAAkB,CAC1D,EAAS,GAAG,CAAC,kBACb,EAAS,GAAG,CAAC,kBACb,EAAS,GAAG,CAAC,WACb,EAAS,GAAG,CAAC,YACb,EAAS,GAAG,CAAC,aAEF,WAAW,CAApB,IACF,EAAS,GAAG,CAAC,kBACb,EAAS,GAAG,CAAC,mBAIjB,OAAO,MAAM,IAAI,CAAC,EACpB,EAiFsB,EAAA,EAET,MAAM,CAAE,MAAO,CAAE,QAAS,EAAE,CAAgB,MAAM,CAAK,EAElE,IAAM,EAtHR,AAsHc,SAtHL,EACP,IAAM,EAAM,EAAA,OAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,GAAI,SAAU,sBAC/C,GAAI,CAAC,EAAA,OAAE,CAAC,UAAU,CAAC,GACjB,GADuB,GACjB,AAAI,MAAM,uEAGlB,OAAO,KAAK,KAAK,CADL,AACM,EADN,OAAE,CAAC,YAAY,CAAC,EAAK,QAEnC,IAgHQ,EAAqB,EAAE,CAE7B,IAAK,IAAM,KAAQ,EAAI,KAAK,CAAE,CAE5B,IAAM,EADY,AACA,GADgB,EAAK,KAAK,GAAK,EACnB,EAAI,GAAgB,EAAK,KAAK,CAAC,UAAU,CAAC,EAAa,KAAK,CAAC,IAAI,CAAC,EAAE,EAAI,IAAM,EAAI,EAG1G,EAAiB,EAAK,KAAK,CAAC,WAAW,GACzC,EAAiB,EACrB,IAAK,IAAM,KAAQ,EACb,EAAe,EADK,MACG,CAAC,KAC1B,EADiC,EACf,EAItB,CAJyB,GAIpB,IAAM,KAAW,EAAK,QAAQ,CAAE,CACnC,GAAI,CAAC,EAAQ,CALyC,KAKnC,CAAE,SACrB,IAAM,EAAQ,AAnEpB,SAAS,AAAa,CAAe,CAAE,CAAuB,CAAE,CAAiB,EAC/E,IAAM,EAAa,EAAQ,KAAK,CAAC,WAAW,GACtC,EAAe,CAAC,EAAQ,OAAO,EAAI,EAAA,CAAE,CAAE,WAAW,GAClD,EAAM,CAAA,EAAG,EAAW,CAAC,EAAE,EAAA,CAAc,CACvC,EAAQ,EAEZ,IAAK,IAAM,KAAK,EAAO,CACrB,GAAI,CAAC,EAAG,SAGJ,IAAe,GAAK,EAAW,QAAQ,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC,GAAK,EAAW,UAAU,CAAC,CAAA,EAAG,EAAE,CAAC,CAAC,GAAK,EAAW,QAAQ,CAAC,CAAC,CAAC,EAAE,EAAA,CAAG,EACpH,CADuH,EAC9G,EACA,CADG,CACQ,QAAQ,CAAC,IAAI,CACjC,IAAS,EAIX,CAJc,GAIR,EAAK,AAAI,OAAO,CAAC,GAAG,EAAE,EAN4B,AAM1B,EAJM,CAIH,CAAC,CAAE,MAC9B,EAAU,EAAI,KAAK,CAAC,GAM1B,GALI,IACF,GAA0B,EADf,EACF,EAAQ,MAAM,AAAG,EAIxB,CAJ6B,CAI3B,MAAM,EAAI,EAAG,CACjB,IAAM,EAAgB,AAAJ,OAAW,EAAG,CAL2B,KAMrD,EAAiB,EAAI,KAAK,CAAC,GAC7B,GAAkB,EAAe,MAAM,EAAI,CAAD,EAAU,SAAU,CAAC,GAAG,AACpE,GAAS,CAAC,EAAe,MAAM,EAAI,CAAD,EAAU,SAAU,CAAC,CAAC,CAAI,EAAA,CAEhE,CACF,CAEA,OAAO,KAAK,KAAK,CAAC,EAAQ,EAC5B,EAiCiC,EAAO,EAAS,EAAY,GACnD,GAAS,GACb,AADgB,EACT,IAAI,CAAC,CACV,MAAO,EAAQ,KAAK,CACpB,KAAM,CAAA,EAAG,EAAK,KAAK,CAAC,CAAC,EAAE,EAAQ,MAAM,CAAA,CAAE,CACvC,IAAK,EAAQ,OAAO,CAAG,EAAQ,OAAO,CAAC,KAAK,CAAC,EAAG,KAAO,iCACvD,UAAW,EAAK,KAAK,CACrB,UAAW,EAAK,KAAK,CACrB,OAAQ,EAAQ,MAAM,CACtB,OACF,EACF,CAGI,GAAkB,GAAK,CAAC,EAAO,IAAI,CAAC,GAAK,EAAE,SAAS,GAAK,EAAK,KAAK,GAAG,AACxE,EAAO,IAAI,CAAC,CACV,MAAO,EAAK,KAAK,CACjB,KAAM,EAAK,KAAK,CAChB,IAAK,CAAC,WAAW,EAAE,EAAK,KAAK,CAAA,CAAE,CAC/B,UAAW,EAAK,KAAK,CACrB,UAAW,EAAK,KAAK,CACrB,OAAQ,GACR,MAAO,CACT,EAEJ,CAEA,EAAO,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,KAAK,CAAG,EAAE,KAAK,EACvC,IAAM,EAAM,EAAO,KAAK,CAAC,EAAG,GAEtB,EAAsB,IAAf,EAAI,MAAM,EAAU,CAAG,CAAC,EAAE,CAAC,KAAK,CAAG,EAChD,MAAO,CAAE,QAAS,OAAK,CAAK,CAC9B,CCxIA,eAAe,EACb,CAAc,CACd,CAAiE,EAEjE,IAAM,EAAM,QAAQ,GAAG,CAAC,cAAc,CAChC,EAAW,MAAM,MAAM,6CAA8C,CACzE,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,cAAe,CAAC,OAAO,EAAE,EAAA,CAAK,AAChC,EACA,KAAM,KAAK,SAAS,CAAC,CACnB,MAAO,EAAO,KAAK,CACnB,SAAU,CACR,CACE,KAAM,SACN,QAAS,CAAC,kfAAkf,CAAC,AAC/f,EACA,CAAE,KAAM,OAAQ,QAAS,CAAO,EACjC,CACD,WAAY,EAAO,SAAS,CAC5B,YAAa,EAAO,WAAW,AACjC,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,kBAAkB,EAAE,EAAS,MAAM,CAAC,CAAC,EAAE,EAAA,CAAO,CACjE,CAEA,IAAM,EAAO,MAAM,EAAS,IAAI,GAIhC,MAAO,CAAE,OAHM,EAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAW,GAGrC,WAFE,EAAK,KAAK,EAAE,aAEF,SAAU,QAAS,CAClD,CAKA,eAAe,EACb,CAAc,CACd,CAAiE,EAEjE,IAAM,EAAM,QAAQ,GAAG,CAAC,gBAAgB,CAClC,EAAW,MAAM,MAAM,+CAAgD,CAC3E,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,cAAe,CAAC,OAAO,EAAE,EAAA,CAAK,AAChC,EACA,KAAM,KAAK,SAAS,CAAC,CACnB,MAAO,EAAO,KAAK,CACnB,SAAU,CACR,CACE,KAAM,SACN,QAAS,CAAC,kfAAkf,CAAC,AAC/f,EACA,CAAE,KAAM,OAAQ,QAAS,CAAO,EACjC,CACD,WAAY,EAAO,SAAS,CAC5B,YAAa,EAAO,WAAW,AACjC,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAU,AAAJ,MAAU,CAAC,uBAAuB,EAAE,EAAS,MAAM,CAAC,CAAC,EAAE,EAAA,CAAO,CACtE,CAEA,IAAM,EAAO,MAAM,EAAS,IAAI,GAIhC,MAAO,CAAE,OAHM,EAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAW,GAGrC,WAFE,EAAK,KAAK,EAAE,aAEF,SAAU,UAAW,CACpD,CAKA,eAAe,EACb,CAAc,CACd,CAAiE,EAEjE,IAAM,EAAU,QAAQ,GAAG,CAAC,eAAe,EAAI,yBACzC,EAAW,MAAM,MAAM,CAAA,EAAG,EAAQ,SAAS,CAAC,CAAE,CAClD,OAAQ,OACR,QAAS,CAAE,eAAgB,kBAAmB,EAC9C,KAAM,KAAK,SAAS,CAAC,CACnB,MAAO,EAAO,KAAK,CACnB,SAAU,CACR,CACE,KAAM,SACN,QAAS,CAAC,kfAAkf,CAAC,AAC/f,EACA,CAAE,KAAM,OAAQ,QAAS,CAAO,EACjC,CACD,QAAS,CACP,YAAa,EAAO,SAAS,CAC7B,YAAa,EAAO,WAAW,AACjC,EACA,OAAQ,EACV,EACF,GAEA,GAAI,CAAC,EAAS,EAAE,CAAE,CAChB,IAAM,EAAQ,MAAM,EAAS,IAAI,EACjC,OAAM,AAAI,MAAM,CAAC,kBAAkB,EAAE,EAAS,MAAM,CAAC,CAAC,EAAE,EAAA,CAAO,CACjE,CAEA,IAAM,EAAO,MAAM,EAAS,IAAI,GAGhC,MAAO,CAAE,OAFM,EAAK,OAAO,EAAE,SAAW,GAEvB,SAAU,QAAS,CACtC,CAqDO,eAAe,EACpB,CAAgB,CAChB,CAME,CACF,CAA0D,CAC1D,EAAY,IAAK,EAEjB,QAAM,EApNN,AAAI,OAoNW,CApNH,GAAG,CAAC,cAAc,CACrB,CADuB,AAE5B,SAAU,SACV,MAAO,QAAQ,GAAG,CAAC,YAAY,EAAI,cACnC,UAAW,IACX,YAAa,EACf,EAGE,QAAQ,GAAG,CAAC,gBAAgB,CACvB,CADyB,AAE9B,SAAU,WACV,MAAO,QAAQ,GAAG,CAAC,cAAc,EAAI,yCACrC,UAAW,IACX,YAAa,EACf,EAGE,QAAQ,GAAG,CAAC,eAAe,CACtB,CADwB,AAE7B,SAAU,SACV,MAAO,QAAQ,GAAG,CAAC,YAAY,EAAI,WACnC,UAAW,IACX,YAAa,EACf,EAGK,CAAE,SAAU,MAAO,EA2L1B,GAAwB,QAAQ,CAA5B,EAAO,QAAQ,CACjB,OAAO,KAGT,IAAM,GAvDA,EAAyB,EAAE,CAE7B,CAqDW,EArDS,OACtB,AAD6B,EAChB,IAAI,CAAC,CAAC,cAAc,EAAE,EAAmB,KAAK,CAAC,EAAE,EAAE,AAoDR,EApD2B,QAAQ,EAAI,GAAG,CAAC,CAAC,EAGtG,EAAa,IAAI,CAAC,0CAElB,AA+CwC,EA/CvB,OAAO,CAAC,CAAC,EAAM,KAC9B,IAAM,EAAO,EAAK,OAAO,EAAI,EAAK,IAAI,EAAI,EAAK,GAAG,EAAI,GACtD,EAAa,IAAI,CAAC,CAAC;AAAA,QAAU,EAAE,EAAM,EAAE,EAAE,EAAE,EAAK,KAAK,CAAC,CAAC,CAAC,EACxD,EAAa,IAAI,CAAC,CAAC,KAAK,EAAE,EAAK,IAAI,CAAA,CAAE,EACrC,EAAa,IAAI,CAAC,CAAC,SAAS,EAAE,EAAA,CAAM,CACtC,GAEM,EAAU,EAAa,IAAI,CAAC,MAE3B,CAAC;;UAEA,EAAE,AAoCoB,SApCX;;AAErB,EAAE,QAAQ;;;;;;;;;;OAUH,CAAC,EA0BA,EAAa,IAAI,gBACjB,EAAY,WAAW,IAAM,EAAW,KAAK,GAAI,GAEvD,GAAI,CACF,IAAI,EAEJ,OAAQ,EAAO,QAAQ,EACrB,IAAK,SACH,EAAS,MAAM,EAAmB,EAAQ,GAC1C,KACF,KAAK,WACH,EAAS,MAAM,EAAqB,EAAQ,GAC5C,KACF,KAAK,SACH,EAAS,MAAM,EAAmB,EAAQ,GAC1C,KACF,SACE,OAAO,IACX,CAGA,OADA,aAAa,GACN,CACT,CAAE,MAAO,EAAK,CAEZ,GADA,aAAa,GACT,aAAe,OAAsB,cAAc,CAA3B,EAAI,IAAI,CAClC,MAAM,AAAI,MAAM,wBAElB,OAAM,CACR,CACF"}}]
}